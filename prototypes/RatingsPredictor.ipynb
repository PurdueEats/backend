{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prime-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "wound-presentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "\n",
    "src = np.random.randint(0, 100, 500)\n",
    "dst = np.random.randint(0, 100, 500)\n",
    "ratings = dgl.heterograph(\n",
    "    {('user', 'rating', 'menuItem') : (np.concatenate([src, dst]), np.concatenate([dst, src]))})\n",
    "ratings.nodes['user'].data['feat'] = torch.randn(100, 10)\n",
    "ratings.nodes['menuItem'].data['feat'] = torch.randn(100, 10)\n",
    "ratings.nodes['user'].data['h'] = torch.randn(100, 10)\n",
    "ratings.nodes['menuItem'].data['h'] = torch.randn(100, 10)\n",
    "ratings.edges['rating'].data['label'] = torch.randn(1000, 5)\n",
    "hetero_graph = ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "supposed-percentage",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Node types: ['menuItem', 'user']\n",
      "Edge types: ['rating']\n",
      "Canonical edge types: [('user', 'rating', 'menuItem')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-5.4788e-01, -4.3858e-01,  6.1055e-01,  6.7419e-01, -2.9468e-01,\n",
       "         -2.2180e-01,  7.0531e-01,  2.1755e+00,  6.6196e-01,  2.0971e-01],\n",
       "        [ 9.3083e-01,  4.8017e-01, -6.8178e-01, -4.8535e-01,  3.2071e-01,\n",
       "         -2.5853e-02,  3.0396e-01, -8.5124e-01, -8.7602e-01,  5.1982e-01],\n",
       "        [-1.9595e+00, -9.8200e-01,  1.5850e+00,  9.6900e-01,  4.0175e-02,\n",
       "          1.0325e+00,  2.9664e-01, -1.5458e-04, -9.9686e-02, -3.9723e-01],\n",
       "        [ 2.9910e-01, -1.1362e+00, -9.1420e-01, -5.2920e-02, -1.5072e+00,\n",
       "         -1.2154e-01, -1.6402e-01, -2.6102e-01,  1.7016e+00, -6.5747e-01],\n",
       "        [ 4.8218e-01, -1.8329e-01,  7.5698e-01,  7.3101e-01, -4.1037e-01,\n",
       "          7.4353e-01, -3.0006e-01, -3.2393e-01,  2.9800e-01, -6.1953e-01],\n",
       "        [ 6.3464e-01, -1.1022e-01, -1.8871e-02, -1.9165e+00, -2.0447e-01,\n",
       "          2.6971e+00, -9.0890e-01,  8.7641e-01, -8.5182e-01, -1.0765e+00],\n",
       "        [ 1.4204e+00,  2.1342e-01, -2.7295e-01,  5.8698e-01,  3.9386e-01,\n",
       "         -7.9516e-01,  1.7091e+00,  9.0375e-01, -1.8967e-01, -3.0129e-01],\n",
       "        [-6.0898e-01,  1.4697e-01, -2.0854e-01, -1.8336e-01, -1.1249e+00,\n",
       "         -3.6543e-01,  3.4518e-01, -7.0653e-01,  1.0283e+00,  7.7768e-01],\n",
       "        [-2.1093e+00,  1.5557e+00,  1.2921e+00, -6.4683e-01, -1.8116e+00,\n",
       "         -5.2032e-01, -1.9343e-01, -1.8942e-01,  9.3478e-01,  1.3696e+00],\n",
       "        [-1.7904e+00,  7.5073e-01, -4.5520e-01,  1.1832e+00, -3.1036e-01,\n",
       "          9.9178e-02,  8.3517e-01, -1.8213e+00,  3.2061e-01, -5.6466e-01],\n",
       "        [-1.1925e+00,  2.1228e-01,  3.1434e-01, -8.8624e-01, -7.6185e-02,\n",
       "          1.9630e-01, -1.0370e+00,  9.6245e-01,  1.1960e+00,  1.2457e+00],\n",
       "        [-8.2191e-01, -2.0878e+00,  1.1447e+00, -1.4298e+00, -2.1725e+00,\n",
       "          3.5872e-01,  3.3348e-01, -8.4673e-02, -5.5789e-01, -1.1560e+00],\n",
       "        [ 8.9955e-02,  1.6746e+00,  2.5971e+00,  2.1270e+00,  2.6188e-01,\n",
       "         -4.4517e-01, -6.0931e-01,  4.1866e-01, -1.4335e-01,  4.2989e-01],\n",
       "        [ 5.2575e-01,  7.8618e-01, -2.4021e-01,  4.9184e-01, -2.7357e-01,\n",
       "         -6.2201e-01, -2.6472e-02,  7.3368e-01,  1.8582e+00, -9.6392e-01],\n",
       "        [-1.1299e+00, -1.2113e+00, -3.7987e-01, -7.9842e-01,  1.8586e-01,\n",
       "          4.4201e-01, -2.0585e-01, -9.0724e-01,  3.8433e-01, -9.1304e-01],\n",
       "        [-9.0104e-01,  1.3552e+00, -2.5406e-01,  1.4599e-01,  1.2725e+00,\n",
       "          2.4805e-01, -5.5860e-01, -1.3821e+00, -1.3942e+00, -1.1853e+00],\n",
       "        [-7.1410e-01, -8.1673e-01,  9.2320e-01, -1.2853e-01, -4.0941e-06,\n",
       "          1.6996e-01,  1.3254e-01, -4.7806e-01, -1.1397e+00,  3.3007e-01],\n",
       "        [ 4.2730e-01,  9.0688e-01,  6.8188e-01, -7.4256e-01, -2.4534e-01,\n",
       "         -4.7366e-01,  1.1888e+00, -9.3058e-01, -1.0688e+00,  1.1474e+00],\n",
       "        [ 1.5284e+00,  4.7363e-02, -2.0458e-01, -7.5921e-01, -5.2722e-01,\n",
       "          1.3898e+00,  6.7202e-01,  9.2876e-01,  1.0613e-01,  1.9721e+00],\n",
       "        [ 6.7814e-02, -4.6211e-01, -5.9680e-01,  6.0033e-02, -5.3121e-01,\n",
       "          8.7183e-01,  1.5263e+00,  1.3300e-01, -3.7584e-01, -2.7456e-01],\n",
       "        [-1.0503e-01, -1.3011e+00, -2.9578e-01, -1.5960e+00,  9.8153e-01,\n",
       "          4.3463e-01, -9.1927e-01, -1.4924e+00,  5.2940e-01, -1.0087e+00],\n",
       "        [-7.6624e-01,  9.6380e-01, -1.5420e+00, -1.4623e-02, -1.2445e+00,\n",
       "         -1.5293e+00, -7.5450e-01,  2.2504e-01, -9.0151e-02,  7.0478e-01],\n",
       "        [-2.5205e-01, -3.9699e-01, -1.5152e+00,  1.2859e+00, -6.6521e-01,\n",
       "         -9.4560e-01,  6.1538e-01, -6.8817e-01, -3.7181e-01, -5.9774e-01],\n",
       "        [-1.1581e+00,  8.9330e-02,  8.2406e-02, -9.5931e-01, -1.6848e+00,\n",
       "         -5.5040e-01, -1.0069e+00, -2.9504e+00,  8.0179e-01,  5.3867e-01],\n",
       "        [ 6.1034e-01,  9.2433e-01, -1.6864e+00,  5.7885e-01, -1.1939e+00,\n",
       "         -4.3393e-01, -1.3791e+00,  1.6173e-01,  1.4668e-01,  2.8092e-01],\n",
       "        [-1.3482e-01,  5.2732e-01,  1.5235e+00, -1.0939e+00, -1.3533e-01,\n",
       "         -7.0298e-01, -2.9382e-01, -1.2898e+00,  2.6008e-01,  2.1379e-01],\n",
       "        [ 6.1077e-01, -1.2997e+00, -6.6453e-01, -2.3162e+00,  4.4124e-01,\n",
       "          4.4625e-01,  2.9863e-01,  6.3368e-01, -3.7474e-02,  6.2912e-01],\n",
       "        [ 5.0136e-01, -9.5040e-02, -9.7905e-01, -1.9032e-01,  1.4680e+00,\n",
       "         -7.6640e-01, -5.8171e-01,  1.7299e-01, -6.8302e-01, -1.8694e+00],\n",
       "        [ 5.8964e-01, -7.9876e-01,  1.1459e+00,  1.3486e+00, -2.3231e-02,\n",
       "          2.2340e-01,  1.3199e+00, -2.3992e-01,  8.9899e-01, -2.8712e-01],\n",
       "        [ 7.4832e-01,  8.0491e-02,  5.4356e-01, -1.3659e-02, -8.2012e-01,\n",
       "          6.9829e-01,  9.9362e-02,  8.4795e-01,  2.6350e-02,  4.5929e-01],\n",
       "        [ 2.7421e-01, -1.3418e+00, -6.1655e-01,  4.2006e-01, -1.0515e+00,\n",
       "         -9.4023e-01, -6.0430e-03,  2.2404e+00, -9.4225e-01,  2.4664e-01],\n",
       "        [ 9.3461e-01,  3.2343e-02, -3.0884e-01,  7.2332e-01,  2.3929e+00,\n",
       "         -7.3274e-01, -1.5067e+00, -4.1534e-01, -6.1589e-01,  8.6643e-01],\n",
       "        [-7.4740e-01,  1.5189e+00,  1.4681e+00, -7.5647e-01,  1.4701e+00,\n",
       "         -1.0667e+00, -1.2812e+00,  8.3245e-01, -3.9051e-01,  2.4787e-01],\n",
       "        [ 1.6784e+00, -6.1523e-01,  3.5805e-02, -5.3508e-03, -1.6779e-01,\n",
       "          9.1097e-01, -1.2735e+00, -1.5222e+00,  3.5001e-01, -1.6797e-01],\n",
       "        [-3.7535e-01,  1.4398e+00,  8.6582e-01,  8.2191e-01, -4.6354e-01,\n",
       "          6.5208e-01,  4.4362e-01,  2.4172e-01, -1.4747e+00,  1.0308e-01],\n",
       "        [ 4.7272e-01,  4.7498e-01,  1.0943e+00,  2.0334e+00,  1.1940e-01,\n",
       "         -9.5860e-01, -2.1112e+00, -2.2635e+00,  4.1967e-01,  4.0140e-01],\n",
       "        [ 1.0378e+00,  5.6015e-02, -1.6014e-01,  3.8353e-01, -1.0475e-01,\n",
       "         -4.5958e-01, -8.8104e-01, -1.1206e+00, -8.8937e-01, -1.1596e+00],\n",
       "        [-1.1888e+00,  1.9470e-01,  1.6689e-01,  1.4674e+00, -1.6587e+00,\n",
       "         -3.9170e-01,  7.4107e-01,  5.1487e-01, -7.6323e-01, -6.9345e-01],\n",
       "        [-4.7778e-01, -6.8165e-01, -1.0172e+00, -9.1694e-02,  1.2586e+00,\n",
       "         -4.0418e-01, -1.0761e+00, -1.2601e-01,  3.2937e-01, -1.0876e+00],\n",
       "        [ 1.1889e+00, -1.0050e+00, -5.1168e-02,  1.4142e+00,  2.1001e-01,\n",
       "         -1.2259e+00,  4.3317e-01, -4.6338e-01,  2.1292e+00,  5.1871e-01],\n",
       "        [-5.6918e-01, -1.3131e+00,  1.9834e-02,  3.8011e-01,  2.4303e-01,\n",
       "         -7.2290e-01, -3.5606e-01,  8.4200e-01,  1.0689e+00, -2.1309e-01],\n",
       "        [-8.7529e-01, -8.7528e-01,  4.0063e-01,  1.1173e-01, -1.0442e-01,\n",
       "          1.3753e-01, -1.1595e+00, -2.7307e-01,  3.7357e-01,  7.4343e-02],\n",
       "        [-3.7578e-01,  1.4532e+00,  2.2959e+00,  1.8881e-02, -1.3906e+00,\n",
       "         -7.1373e-02,  2.1588e+00, -8.4292e-01, -4.6518e-01,  1.3577e+00],\n",
       "        [ 4.9615e-01,  1.7727e-01, -2.9310e-01,  4.8976e-01, -1.8544e+00,\n",
       "          1.0725e-01, -1.6152e+00, -1.1278e+00,  1.2918e+00, -1.2540e-01],\n",
       "        [ 1.5210e+00, -4.2534e-01,  1.3046e+00,  6.6908e-01,  5.1818e-01,\n",
       "          1.1818e+00, -6.3214e-01, -1.2070e+00, -1.8708e+00,  7.1310e-01],\n",
       "        [-6.4890e-01,  4.7062e-01,  1.2037e+00,  1.3730e-01,  1.0666e+00,\n",
       "         -1.2164e-01,  1.2466e-01,  5.4590e-01, -7.6292e-01, -2.0490e+00],\n",
       "        [-4.6676e-01,  1.0272e+00,  2.4959e-01, -6.6581e-01, -3.6367e-01,\n",
       "         -1.4679e+00, -6.6761e-01,  1.7749e-02, -2.5381e-01, -1.7266e-01],\n",
       "        [-1.1600e+00, -6.9063e-01,  3.6988e-01,  3.9679e-01,  1.4683e+00,\n",
       "          2.0432e-01, -2.5763e-01, -1.2419e+00, -2.1063e-01, -2.1506e+00],\n",
       "        [-4.3990e-01,  2.4905e-01,  9.6256e-01, -2.7381e-01, -2.6335e-01,\n",
       "         -6.8326e-01,  3.3900e-01,  2.2827e+00, -1.5328e+00,  6.9319e-01],\n",
       "        [-4.9789e-01, -9.7129e-01, -1.7512e+00,  1.5443e+00, -9.1776e-01,\n",
       "         -1.1596e+00, -1.7333e+00, -1.6435e-01, -7.6513e-01, -7.8957e-01],\n",
       "        [ 4.4442e-01, -3.7895e-01,  1.3919e-01, -1.8781e+00,  1.3432e+00,\n",
       "         -9.7202e-03, -6.2177e-01,  2.1167e-01,  2.9121e-02,  3.7981e-01],\n",
       "        [ 1.2598e+00,  1.2993e-01,  1.8681e-01,  2.9544e-01, -1.7801e-01,\n",
       "          7.8962e-01, -4.1043e-02, -1.0964e+00, -2.2912e+00, -3.6685e-02],\n",
       "        [-4.3229e-01,  4.2154e-01,  2.7637e-01,  9.7256e-01,  2.5606e-01,\n",
       "         -4.9182e-01, -7.5774e-01,  1.2207e+00, -8.1117e-01,  5.3785e-01],\n",
       "        [ 2.7853e-01,  4.0943e-01,  7.1153e-01, -3.9306e-01,  6.2166e-01,\n",
       "          2.6734e-01, -5.9901e-01, -1.6077e+00, -1.4933e+00, -6.4960e-01],\n",
       "        [-1.4874e+00,  5.4214e-01,  1.2982e+00,  3.6624e-01,  6.5118e-02,\n",
       "          9.1082e-01, -1.1363e+00, -6.3791e-02,  6.2022e-01, -2.8496e-01],\n",
       "        [ 1.7690e+00,  4.1383e-01,  7.8118e-01, -1.8406e+00, -8.8313e-01,\n",
       "          1.3653e+00, -1.0415e+00,  1.2493e+00, -4.1122e-01,  3.6849e-01],\n",
       "        [ 4.1121e-01,  4.0906e-01,  2.7810e-02, -5.2759e-02, -3.0503e-01,\n",
       "          2.1757e+00,  2.1498e+00,  1.5161e+00,  9.7082e-02,  2.3977e-02],\n",
       "        [-9.9354e-01,  2.4166e-02, -3.6793e-01, -7.3431e-01, -1.0436e-01,\n",
       "         -3.5501e-01,  6.6047e-01,  2.1147e+00,  9.8669e-01,  1.6068e+00],\n",
       "        [ 7.4849e-01,  9.5591e-01,  1.2085e+00,  9.7616e-01, -9.3074e-01,\n",
       "         -9.6427e-01, -3.9077e-01, -9.5922e-01,  3.9286e-02,  1.0304e+00],\n",
       "        [-1.2688e-01,  8.2933e-01, -3.6367e-01,  1.5421e+00,  2.3900e-01,\n",
       "          2.6706e-01, -2.3379e+00,  1.8867e+00,  1.3933e+00,  2.2292e-01],\n",
       "        [-6.2194e-01, -1.0959e+00, -6.6980e-01,  1.0946e-01,  5.3845e-01,\n",
       "          3.9488e-01, -4.7122e-03,  7.5495e-01,  6.6319e-01, -1.6388e+00],\n",
       "        [-1.4360e+00,  1.8135e+00, -3.5700e-01,  5.7723e-01,  1.9714e-01,\n",
       "         -1.1654e+00,  2.0828e+00,  2.0579e+00,  6.2955e-01,  1.2625e-01],\n",
       "        [ 9.8045e-01, -5.2412e-01,  6.6424e-01,  1.2674e+00, -8.9263e-01,\n",
       "          3.3174e-01, -1.3953e+00,  5.7837e-01, -8.4739e-01,  6.2562e-01],\n",
       "        [ 1.2673e-01, -1.0419e+00, -1.0621e+00, -2.4247e-01,  2.1484e-01,\n",
       "          1.5222e-01,  9.2097e-01, -6.4080e-01, -9.0166e-02, -1.8580e+00],\n",
       "        [-1.9092e+00,  8.4402e-01, -3.4952e-01,  7.8813e-01,  5.8676e-01,\n",
       "         -8.9457e-02, -1.3771e-01,  3.5071e-01,  2.2035e-01,  1.5721e+00],\n",
       "        [ 1.3891e+00,  5.4455e-01, -2.0398e+00, -1.9482e-01, -2.2307e+00,\n",
       "         -1.1896e+00,  2.4116e-02, -9.9969e-01,  1.3143e+00, -1.1035e+00],\n",
       "        [ 6.7379e-01,  1.9641e-01, -4.6882e-01, -1.8279e+00, -3.0472e+00,\n",
       "          8.9968e-01, -1.2220e+00,  1.7675e+00, -1.0987e+00,  3.9787e-01],\n",
       "        [ 9.9322e-01, -5.7132e-01, -6.5116e-01, -4.7302e-01, -4.7273e-01,\n",
       "          6.0608e-01, -2.0715e+00,  9.2121e-01, -1.2662e+00,  1.2379e+00],\n",
       "        [ 1.2352e+00, -3.3470e-01, -1.3316e+00, -9.5401e-01,  1.3294e+00,\n",
       "          6.2845e-01, -1.2114e+00, -1.6694e+00,  1.3499e+00, -2.8307e-01],\n",
       "        [-6.9437e-01,  3.7736e-01, -1.6908e+00, -1.0798e+00,  2.4882e+00,\n",
       "         -9.7564e-01, -2.8871e-01,  5.3021e-01, -1.2435e+00,  2.4978e+00],\n",
       "        [-1.2849e+00, -9.4294e-01,  6.3611e-01, -4.7757e-02,  1.3358e+00,\n",
       "          2.7557e-01,  1.7694e+00,  2.6537e-01,  1.3605e+00, -2.5049e+00],\n",
       "        [-9.0316e-01, -4.9247e-01,  2.2782e-01, -1.2285e+00,  6.9765e-01,\n",
       "          9.2874e-01, -8.4735e-01, -1.8395e+00,  6.8508e-02,  1.6715e-01],\n",
       "        [-1.4945e+00, -1.5226e+00, -6.1135e-01,  6.8193e-02, -4.9000e-01,\n",
       "          1.7186e+00, -2.7620e-01, -1.7353e+00, -1.9521e+00, -2.4566e+00],\n",
       "        [-5.4593e-01, -2.0114e+00,  9.0944e-01, -4.1514e-02,  1.8288e-01,\n",
       "          5.8206e-01, -1.6569e-01, -6.3408e-01, -1.6405e-01,  5.4409e-01],\n",
       "        [-5.5357e-01, -1.1479e+00, -1.0780e+00,  2.7851e-02,  9.2352e-02,\n",
       "         -1.0418e+00, -1.1046e+00, -7.9751e-01, -1.3437e+00, -1.3418e+00],\n",
       "        [-9.2735e-01, -1.1837e+00, -1.4330e+00, -5.6099e-01, -1.5724e+00,\n",
       "          5.3563e-01, -4.6564e-01,  1.5815e+00, -6.0880e-01,  7.4031e-02],\n",
       "        [ 1.1138e+00,  5.9976e-01,  5.5338e-01, -7.2643e-01, -6.6730e-01,\n",
       "         -1.7878e-01,  2.1969e-01,  1.5869e+00,  3.1497e-01,  7.4641e-01],\n",
       "        [ 1.4273e+00,  1.1267e-01,  1.7037e+00,  2.8652e-01,  1.6754e-01,\n",
       "          7.8622e-01,  1.0823e+00,  1.0532e+00,  2.9210e-01,  8.7431e-01],\n",
       "        [-1.9867e-01,  2.1209e-01, -1.3658e+00,  6.0682e-01,  9.6503e-01,\n",
       "         -1.5635e+00,  9.0671e-01,  1.0361e+00, -1.8687e-01,  1.4148e+00],\n",
       "        [-1.3365e+00, -2.2748e-01,  1.9203e+00,  1.4367e+00, -7.4736e-01,\n",
       "          1.8785e+00, -4.6543e-01, -4.6480e-01, -3.9278e-01, -6.9750e-01],\n",
       "        [ 2.3588e+00,  2.0922e+00,  4.9244e-01,  1.5307e+00, -6.1421e-01,\n",
       "          4.5158e-01, -1.7667e+00, -3.8839e-01,  8.8515e-01, -1.6962e+00],\n",
       "        [ 9.6697e-02,  1.7569e+00,  6.2282e-01,  1.1940e+00, -1.9768e-01,\n",
       "          5.1285e-02,  1.9879e+00,  1.0230e+00, -4.0550e-01,  3.2110e-02],\n",
       "        [-4.0844e-01, -1.1425e+00,  7.8181e-02, -6.8938e-02,  7.4317e-01,\n",
       "         -8.1076e-01,  1.6128e+00,  7.3716e-01, -1.3705e+00,  1.6466e+00],\n",
       "        [ 7.4923e-01,  2.1075e+00, -1.0391e+00,  4.6874e-01, -1.0014e+00,\n",
       "         -1.4612e+00, -1.3998e+00, -3.8517e-01,  1.5031e-02, -1.4827e+00],\n",
       "        [ 2.5060e+00,  6.2938e-01, -2.3298e-01, -1.3819e+00,  7.1295e-01,\n",
       "          7.8995e-01,  5.4390e-01, -2.3281e-01,  9.2047e-01,  3.2347e-01],\n",
       "        [ 3.3172e-02, -2.6707e-01, -8.3297e-01,  4.4695e-01,  1.0972e-01,\n",
       "         -5.8754e-01, -2.0221e-02,  4.8871e-01, -1.9042e+00, -1.0694e+00],\n",
       "        [-6.4896e-01, -8.1467e-01,  2.1708e+00,  1.4236e-01,  2.1992e+00,\n",
       "          4.3163e-01, -2.1206e+00,  1.5122e+00, -4.1193e-01,  6.6376e-01],\n",
       "        [-3.6465e-02, -9.6384e-01,  2.4906e+00,  8.7066e-01,  4.2971e-01,\n",
       "         -6.4090e-01, -3.3968e-01, -6.4555e-01, -9.8476e-01, -1.4552e-01],\n",
       "        [ 1.1162e+00,  1.0737e+00,  2.0064e+00,  4.3918e-01,  3.0526e+00,\n",
       "         -1.3106e+00,  3.0732e-01,  1.0605e+00, -1.6545e-01, -9.2148e-01],\n",
       "        [ 5.2463e-01, -1.4195e-01,  1.7733e+00, -1.7014e+00,  1.9399e+00,\n",
       "         -9.0237e-01,  1.9728e+00, -4.4721e-01, -7.8347e-01,  5.8553e-02],\n",
       "        [-1.7538e-01, -2.1053e+00, -2.0292e+00,  1.0970e+00, -6.3998e-01,\n",
       "         -5.5746e-02, -1.4632e+00, -1.3090e-02,  9.0561e-01, -6.7188e-01],\n",
       "        [-8.4007e-01,  7.3887e-01,  1.0144e+00, -2.4679e-01,  6.2939e-01,\n",
       "         -2.1007e+00,  2.3370e-01,  1.5071e-01,  3.1506e-01, -6.9483e-01],\n",
       "        [ 6.5968e-02, -1.4817e+00, -1.1425e+00,  1.4127e-01,  8.2405e-01,\n",
       "          1.2982e+00,  2.9861e+00, -3.6661e-01, -3.0743e-01,  3.1886e+00],\n",
       "        [-2.6142e-01, -5.6201e-01,  4.7523e-01, -3.7398e-01,  3.7532e-01,\n",
       "         -1.9369e+00, -7.7227e-02,  6.8400e-01,  7.3660e-01,  1.0874e+00],\n",
       "        [ 1.5070e+00, -1.4767e+00,  7.4517e-01,  2.3414e-01,  9.4245e-01,\n",
       "          8.6426e-02, -1.5881e+00, -1.2315e+00,  1.3495e+00,  7.2790e-01],\n",
       "        [-5.7545e-01,  2.2944e+00, -1.0164e+00,  1.7963e+00, -1.0783e+00,\n",
       "         -4.2864e-01,  8.8893e-02, -1.2733e+00,  8.6728e-01,  5.0191e-01],\n",
       "        [-1.0442e+00, -6.3640e-01,  8.8002e-01, -3.0086e-01, -1.0720e+00,\n",
       "         -1.7623e+00,  5.3654e-01,  7.5460e-01,  5.8881e-01,  5.8209e-01],\n",
       "        [ 8.8573e-01,  1.9333e+00,  7.3403e-01,  1.5016e-01, -7.1262e-01,\n",
       "         -7.1101e-02,  1.1850e+00,  6.6920e-01,  6.8636e-01,  1.1543e+00],\n",
       "        [-1.6415e+00,  1.0159e+00,  8.4265e-01, -7.4339e-01, -7.7402e-01,\n",
       "         -9.7467e-01, -4.2905e-01, -1.3693e+00, -4.8943e-01,  1.6876e+00],\n",
       "        [ 4.8783e-01, -4.7995e-01,  7.9455e-01,  1.1564e+00, -4.6719e-01,\n",
       "          3.3346e-01,  6.1762e-01,  2.0566e+00,  1.5261e+00, -7.2997e-01]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ratings.num_nodes())\n",
    "print('Node types:', ratings.ntypes)\n",
    "print('Edge types:', ratings.etypes)\n",
    "print('Canonical edge types:', ratings.canonical_etypes)\n",
    "ratings.nodes['user'].data['h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "living-commander",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('user', 'rating', 'menuItem')\n",
      "EdgeSpace(data={'label': tensor([[ 2.0302, -0.7687,  1.1129, -1.5148, -0.3823],\n",
      "        [-0.5129,  1.4071,  1.0234,  0.3360,  0.3705],\n",
      "        [-1.5700, -0.1940,  0.8504,  2.4718,  0.9155],\n",
      "        ...,\n",
      "        [-1.4285, -1.2889, -0.8775,  1.9161, -1.5724],\n",
      "        [ 0.2555, -1.5693, -1.9820,  0.2515,  0.4006],\n",
      "        [ 0.2942,  0.8836,  1.1265,  1.4447, -1.3095]])})\n"
     ]
    }
   ],
   "source": [
    "ratings.edges(etype='rating')\n",
    "for c_etype in ratings.canonical_etypes:\n",
    "    srctype, etype, dsttype = c_etype\n",
    "    print(c_etype)\n",
    "    print(ratings.edges[etype])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "rotary-motel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('user', 'menuItem')]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AGraph' object has no attribute 'view'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-207-9fd53098a8d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetagraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplot_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetagraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-207-9fd53098a8d7>\u001b[0m in \u001b[0;36mplot_graph\u001b[0;34m(nxg)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'graph.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetagraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AGraph' object has no attribute 'view'"
     ]
    }
   ],
   "source": [
    "import pygraphviz as pgv\n",
    "from IPython.display import display\n",
    "\n",
    "def plot_graph(nxg):\n",
    "    ag = pgv.AGraph(strict=False, directed=True)\n",
    "    for u, v, k in nxg.edges(keys=True):\n",
    "        ag.add_edge(u, v, label=k)\n",
    "    ag.layout('dot')\n",
    "    ag.draw('graph.png')\n",
    "    ag.view()\n",
    " \n",
    "print(ratings.metagraph().edges())\n",
    "plot_graph(ratings.metagraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "regional-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, in_features, out_classes):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(in_features * 2, out_classes)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        h_u = edges.src['h']\n",
    "        h_v = edges.dst['h']\n",
    "        score = self.W(torch.cat([h_u, h_v], 1))\n",
    "        return {'score': score}\n",
    "\n",
    "    def forward(self, graph, h, etype):\n",
    "        # h contains the node representations for each edge type computed from\n",
    "        # the GNN for heterogeneous graphs defined in the node classification\n",
    "        # section (Section 5.1).\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h   # assigns 'h' of all node types in one shot\n",
    "            print(h)\n",
    "            graph.apply_edges(self.apply_edges, etype=etype)\n",
    "            return graph.edges[etype].data['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "double-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroDotProductPredictor(nn.Module):\n",
    "    def forward(self, graph, h, etype):\n",
    "        # h contains the node representations for each edge type computed from\n",
    "        # the GNN for heterogeneous graphs defined in the node classification\n",
    "        # section (Section 5.1).\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h   # assigns 'h' of all node types in one shot\n",
    "            print(graph.ndata['h'])\n",
    "            graph.apply_edges(fn.u_dot_v('h', 'h', 'score'), etype=etype)\n",
    "            return graph.edges[etype].data['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "built-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCN(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats, rel_names):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = dgl.nn.HeteroGraphConv({\n",
    "            rel: dgl.nn.GraphConv(in_feats, hid_feats)\n",
    "            for rel in rel_names}, aggregate='sum')\n",
    "        self.conv2 = dgl.nn.HeteroGraphConv({\n",
    "            rel: dgl.nn.GraphConv(hid_feats, out_feats)\n",
    "            for rel in rel_names}, aggregate='sum')\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        # inputs are features of nodes\n",
    "        h = self.conv1(graph, inputs)\n",
    "        h = {k: F.relu(v) for k, v in h.items()}\n",
    "        h = self.conv2(graph, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "animated-control",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, rel_names):\n",
    "        super().__init__()\n",
    "        self.sage = RGCN(in_features, hidden_features, out_features, rel_names)\n",
    "        self.pred = MLPPredictor(in_features, out_features)\n",
    "    def forward(self, g, x, etype):\n",
    "        h = self.sage(g, x)\n",
    "        return self.pred(g, h, etype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "normal-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(10, 20, 5, hetero_graph.etypes)\n",
    "#import networkx as nx\n",
    "#nx_G = ratings.to_networkx()\n",
    "#pos = nx.kamada_kawai_layout(nx_G)\n",
    "#nx.draw(nx_G, pos, with_labels=True, node_color=[[.7, .7, .7]])\n",
    "user_feats = hetero_graph.nodes['user'].data['feat']\n",
    "item_feats = hetero_graph.nodes['menuItem'].data['feat']\n",
    "label = hetero_graph.edges['rating'].data['label']\n",
    "node_features = {'user': user_feats, 'menuItem': item_feats}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ahead-scope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "In epoch 0, loss: 1.3585706949234009\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 5, loss: 1.332624912261963\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 10, loss: 1.3079216480255127\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 15, loss: 1.2844899892807007\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 20, loss: 1.2623289823532104\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 25, loss: 1.2414274215698242\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 30, loss: 1.2217588424682617\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 35, loss: 1.2032859325408936\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 40, loss: 1.1859662532806396\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 45, loss: 1.1697523593902588\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 50, loss: 1.1545902490615845\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 55, loss: 1.1404242515563965\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 60, loss: 1.1271979808807373\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 65, loss: 1.114855170249939\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 70, loss: 1.10334050655365\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 75, loss: 1.0926014184951782\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 80, loss: 1.082587718963623\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 85, loss: 1.0732511281967163\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 90, loss: 1.0645477771759033\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 95, loss: 1.056435465812683\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 100, loss: 1.0488755702972412\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 105, loss: 1.0418322086334229\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 110, loss: 1.0352715253829956\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 115, loss: 1.0291630029678345\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 120, loss: 1.0234770774841309\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 125, loss: 1.0181869268417358\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 130, loss: 1.013267159461975\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 135, loss: 1.0086944103240967\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 140, loss: 1.0044463872909546\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 145, loss: 1.000502109527588\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 150, loss: 0.9968425631523132\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 155, loss: 0.9934489130973816\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 160, loss: 0.9903039932250977\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 165, loss: 0.9873915910720825\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 170, loss: 0.984696090221405\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 175, loss: 0.9822035431861877\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 180, loss: 0.9798997044563293\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 185, loss: 0.977772057056427\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 190, loss: 0.9758086204528809\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 195, loss: 0.9739975333213806\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 200, loss: 0.9723286032676697\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 205, loss: 0.9707916975021362\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 210, loss: 0.9693770408630371\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 215, loss: 0.9680760502815247\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 220, loss: 0.9668802618980408\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 225, loss: 0.9657820463180542\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 230, loss: 0.9647740125656128\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 235, loss: 0.9638492465019226\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 240, loss: 0.9630014896392822\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 245, loss: 0.9622247815132141\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 250, loss: 0.9615136981010437\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 255, loss: 0.9608628749847412\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 260, loss: 0.9602677822113037\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 265, loss: 0.9597236514091492\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 270, loss: 0.959226667881012\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 275, loss: 0.9587727785110474\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 280, loss: 0.9583587050437927\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 285, loss: 0.957980751991272\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 290, loss: 0.9576362371444702\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 295, loss: 0.957322359085083\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 300, loss: 0.9570362567901611\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 305, loss: 0.9567757844924927\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 310, loss: 0.9565386772155762\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 315, loss: 0.9563228487968445\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 320, loss: 0.9561266899108887\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 325, loss: 0.9559482336044312\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 330, loss: 0.9557859301567078\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 335, loss: 0.9556384682655334\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 340, loss: 0.9555044770240784\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 345, loss: 0.9553828239440918\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 350, loss: 0.9552722573280334\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 355, loss: 0.9551717638969421\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 360, loss: 0.9550806879997253\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 365, loss: 0.9549979567527771\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 370, loss: 0.9549229741096497\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 375, loss: 0.9548547863960266\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 380, loss: 0.9547929763793945\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 385, loss: 0.9547368884086609\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 390, loss: 0.9546859264373779\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 395, loss: 0.9546398520469666\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 400, loss: 0.9545978307723999\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 405, loss: 0.9545597434043884\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 410, loss: 0.9545251727104187\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 415, loss: 0.9544939398765564\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 420, loss: 0.9544655084609985\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 425, loss: 0.9544397592544556\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 430, loss: 0.9544162154197693\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 435, loss: 0.9543949365615845\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 440, loss: 0.9543755650520325\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 445, loss: 0.9543579816818237\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 450, loss: 0.9543420672416687\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 455, loss: 0.9543275237083435\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 460, loss: 0.9543144702911377\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 465, loss: 0.9543023705482483\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 470, loss: 0.9542915225028992\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 475, loss: 0.9542815685272217\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 480, loss: 0.9542726278305054\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 485, loss: 0.9542643427848816\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 490, loss: 0.9542568325996399\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 495, loss: 0.9542499780654907\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 500, loss: 0.9542437791824341\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 505, loss: 0.9542380571365356\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 510, loss: 0.954232931137085\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 515, loss: 0.9542283415794373\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 520, loss: 0.9542238116264343\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 525, loss: 0.9542199969291687\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 530, loss: 0.9542164206504822\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 535, loss: 0.9542130827903748\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 540, loss: 0.9542101621627808\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 545, loss: 0.9542074203491211\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 550, loss: 0.9542048573493958\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 555, loss: 0.9542026519775391\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 560, loss: 0.9542005062103271\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 565, loss: 0.9541985392570496\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 570, loss: 0.9541967511177063\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 575, loss: 0.9541952013969421\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 580, loss: 0.954193651676178\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 585, loss: 0.9541923999786377\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 590, loss: 0.9541910886764526\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 595, loss: 0.9541899561882019\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 600, loss: 0.9541889429092407\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 605, loss: 0.9541879892349243\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 610, loss: 0.9541870355606079\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 615, loss: 0.954186201095581\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 620, loss: 0.954185426235199\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 625, loss: 0.954184889793396\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 630, loss: 0.9541841745376587\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 635, loss: 0.9541835784912109\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 640, loss: 0.9541829824447632\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 645, loss: 0.9541826248168945\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 650, loss: 0.9541821479797363\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 655, loss: 0.9541816115379333\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 660, loss: 0.9541813731193542\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 665, loss: 0.9541808366775513\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 670, loss: 0.9541806578636169\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 675, loss: 0.9541803598403931\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 680, loss: 0.9541800022125244\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 685, loss: 0.9541797637939453\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 690, loss: 0.9541794657707214\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 695, loss: 0.9541792273521423\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 700, loss: 0.9541791081428528\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 705, loss: 0.9541789293289185\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 710, loss: 0.9541788101196289\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 715, loss: 0.9541786909103394\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 720, loss: 0.954178512096405\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 725, loss: 0.9541783332824707\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 730, loss: 0.9541781544685364\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 735, loss: 0.9541781544685364\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 740, loss: 0.9541779160499573\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 745, loss: 0.9541778564453125\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 750, loss: 0.954177737236023\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 755, loss: 0.954177737236023\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 760, loss: 0.9541775584220886\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "In epoch 765, loss: 0.9541775584220886\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 770, loss: 0.9541774392127991\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 775, loss: 0.9541773200035095\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 780, loss: 0.9541773200035095\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 785, loss: 0.9541773200035095\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 790, loss: 0.9541772603988647\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 795, loss: 0.9541771411895752\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 800, loss: 0.9541771411895752\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 805, loss: 0.9541771411895752\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 810, loss: 0.9541771411895752\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 815, loss: 0.9541769623756409\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 820, loss: 0.9541769623756409\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 825, loss: 0.9541769623756409\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 830, loss: 0.9541769623756409\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 835, loss: 0.9541769623756409\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 840, loss: 0.9541769623756409\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 845, loss: 0.9541768431663513\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 850, loss: 0.9541768431663513\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 855, loss: 0.9541769623756409\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 860, loss: 0.9541767835617065\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 865, loss: 0.9541768431663513\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 870, loss: 0.9541767835617065\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 875, loss: 0.9541767835617065\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 880, loss: 0.9541767835617065\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 885, loss: 0.9541768431663513\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 890, loss: 0.9541767835617065\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 895, loss: 0.9541767835617065\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 900, loss: 0.9541767835617065\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 905, loss: 0.954176664352417\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 910, loss: 0.9541767835617065\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 915, loss: 0.9541767835617065\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 920, loss: 0.9541767835617065\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 925, loss: 0.9541767835617065\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 930, loss: 0.9541767835617065\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 935, loss: 0.9541767835617065\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 940, loss: 0.954176664352417\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 945, loss: 0.9541767835617065\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 950, loss: 0.954176664352417\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 955, loss: 0.9541767835617065\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 960, loss: 0.954176664352417\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 965, loss: 0.954176664352417\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 970, loss: 0.9541767835617065\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 975, loss: 0.9541767835617065\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 980, loss: 0.954176664352417\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 985, loss: 0.9541765451431274\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 990, loss: 0.9541767835617065\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "In epoch 995, loss: 0.9541767835617065\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "import dgl.function as fn\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "for epoch in range(1000):\n",
    "    pred = model(ratings, node_features, 'rating')\n",
    "    loss = ((pred - label) ** 2).mean()\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if epoch % 5 == 0:\n",
    "        print('In epoch {}, loss: {}'.format(epoch, loss))\n",
    "    #print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-armenia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
